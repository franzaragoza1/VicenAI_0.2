# üéôÔ∏è Voice Pipeline Setup Guide

Gu√≠a completa para configurar el nuevo pipeline de voz **STT ‚Üí LLM ‚Üí TTS** (Deepgram + Qwen3 + Cartesia).

---

## üìã Requisitos

### API Keys Necesarias

Necesitas crear cuentas y obtener API keys de 3 servicios:

#### 1. **Deepgram** (Speech-to-Text)
- **URL**: https://console.deepgram.com/signup
- **Plan**: Free tier incluye $200 cr√©ditos (suficiente para testing)
- **Coste**: $0.0043/minuto = ~$0.26/hora
- **C√≥mo obtener la key**:
  1. Crear cuenta en Deepgram
  2. Ir a "API Keys" en el dashboard
  3. Crear nueva key (copiar y guardar)

#### 2. **OpenRouter** (LLM Gateway)
- **URL**: https://openrouter.ai/auth/signup
- **Plan**: Pay-as-you-go (a√±adir $5-10 iniciales)
- **Coste**: ~$0.004/hora con Qwen3-235B
- **C√≥mo obtener la key**:
  1. Crear cuenta en OpenRouter
  2. A√±adir cr√©ditos: https://openrouter.ai/credits
  3. Ir a "Keys" ‚Üí Crear nueva key
  4. Copiar y guardar la key

#### 3. **Cartesia** (Text-to-Speech)
- **URL**: https://cartesia.ai/signup
- **Plan**: Free tier incluye cr√©ditos iniciales
- **Coste**: $0.03/minuto = ~$1.80/hora
- **C√≥mo obtener la key**:
  1. Crear cuenta en Cartesia
  2. Ir a "API Keys" en dashboard
  3. Crear nueva key (copiar y guardar)

---

## ‚öôÔ∏è Configuraci√≥n

### 1. Server Configuration

Crea el archivo `server/.env` (o edita el existente):

```bash
# Voice Pipeline API Keys
DEEPGRAM_API_KEY=tu_deepgram_key_aqui
DEEPGRAM_MODEL=nova-2

OPENROUTER_API_KEY=tu_openrouter_key_aqui
OPENROUTER_MODEL=qwen/qwen3-235b-a22b-2507:nitro
OPENROUTER_FALLBACK_MODEL=openai/gpt-4o-mini

CARTESIA_API_KEY=tu_cartesia_key_aqui
CARTESIA_MODEL_ID=sonic-3-turbo
CARTESIA_VOICE_ID=a0e99841-438c-4a64-b679-ae501e7d6091

# Logging (opcional)
VOICE_LOG_LEVEL=info
```

**Importante**: Las API keys NUNCA deben ir en el cliente, solo en el servidor.

### 2. Client Configuration

Crea el archivo `client/.env` (o edita el existente):

```bash
# Voice Engine Selection
VITE_VOICE_ENGINE=pipeline
```

**Opciones**:
- `pipeline`: Nuevo pipeline modular (Deepgram + Qwen3 + Cartesia)
- `gemini`: Gemini Live original (fallback)

---

## üöÄ Uso

### Arrancar el Servidor

```bash
npm start
```

El servidor arrancar√° en `http://localhost:8081` con el endpoint WebSocket `/voice`.

### Logs Esperados

Si todo est√° configurado correctamente, ver√°s:

```
[Server] Listening on http://localhost:8081
[Voice] Session created: voice-1
[DeepgramSTT] Connected successfully
[CartesiaTTS] Connected successfully
[Voice] STT connected for session voice-1
[Voice] TTS connected for session voice-1
```

### Errores Comunes

**Error**: `DEEPGRAM_API_KEY not set in environment`
- **Soluci√≥n**: Verifica que `.env` existe en `server/` y contiene la key

**Error**: `OpenRouter API error: 401`
- **Soluci√≥n**: API key incorrecta o sin cr√©ditos. Verifica en https://openrouter.ai/credits

**Error**: `Cartesia WebSocket closed: 1002`
- **Soluci√≥n**: API key incorrecta. Verifica en https://cartesia.ai/console

---

## üéÆ Controles

### PTT (Push-to-Talk)
- **F14**: Toggle mic ON/OFF
- El pipeline usa **open-mic + endpointing** (300ms silencio finaliza turno)
- PTT OFF no corta la voz del asistente (solo VAD puede interrumpir)

### Barge-in (Interrumpir al Asistente)
- Habla mientras el asistente est√° hablando
- VAD detecta tu voz ‚Üí interrumpe TTS con fade-out < 150ms
- Empieza nueva captura autom√°ticamente

---

## üí∞ Costes Estimados

Para una **sesi√≥n de 1 hora** de carrera con ~20 interacciones:

| Servicio | Uso Estimado | Coste |
|----------|--------------|-------|
| **Deepgram STT** | 10 min piloto hablando | $0.043 |
| **Qwen3 LLM** | 20 queries (~450 tokens/query) | $0.004 |
| **Cartesia TTS** | 8 min respuestas TTS | $0.24 |
| **TOTAL** | | **$0.287/hora** |

**Comparaci√≥n**: Gemini Live costaba ~$6-10/hora estimado (95-97% ahorro).

---

## üêõ Debugging

### Habilitar Logs Verbose

En `server/.env`:
```bash
VOICE_LOG_LEVEL=debug
```

### Ver Estado del Pipeline

Los logs mostrar√°n:
```
[Voice] Mic state changed: true
[DeepgramSTT] Partial transcript: "¬øCu√°l es mi gap?"
[DeepgramSTT] Final transcript: "¬øCu√°l es mi gap con el de delante?"
[Voice] STT final ‚Üí triggering LLM
[OpenRouterLLM] Sending message to qwen/qwen3-235b-a22b-2507:nitro
[OpenRouterLLM] Stream completed in 850ms
[CartesiaTTS] Synthesizing: "Tienes 2.3 segundos con el rival de delante."
```

### Verificar Conexiones

En los logs del server al inicio:
- `[DeepgramSTT] Connected successfully` ‚úÖ
- `[CartesiaTTS] Connected successfully` ‚úÖ
- `[Voice] STT connected for session voice-1` ‚úÖ

Si alguna falta, revisa las API keys.

---

## üîÑ Rollback a Gemini Live

Si necesitas volver al sistema anterior:

1. Cambiar `client/.env`:
   ```bash
   VITE_VOICE_ENGINE=gemini
   ```

2. Reiniciar la app

**Tiempo de rollback**: < 5 minutos

---

## üìä M√©tricas de Calidad

### Latencia Objetivo
- **PTT ON ‚Üí primer partial STT**: < 500ms
- **Fin de frase ‚Üí inicio audio TTS**: < 1.5s promedio
- **Barge-in fade-out**: < 150ms

### Calidad de Output
- ‚úÖ 100% espa√±ol de Espa√±a
- ‚úÖ Sin pre√°mbulos ("voy a...", "let me...")
- ‚úÖ Estilo radio F1 (1-3 frases)
- ‚úÖ Sin markdown/listas/t√≠tulos

---

## ‚ùì FAQ

**P: ¬øNecesito las 3 API keys para que funcione?**
R: S√≠, el pipeline necesita STT + LLM + TTS. Sin alguna, la sesi√≥n de voz no se iniciar√°.

**P: ¬øPuedo usar otros modelos LLM?**
R: S√≠, cambia `OPENROUTER_MODEL` en `.env`. Opciones recomendadas:
- `qwen/qwen3-235b-a22b-2507:nitro` (actual, muy r√°pido)
- `openai/gpt-4o-mini` (m√°s caro pero muy fiable)
- `meta-llama/llama-4-maverick:nitro` (experimental)

**P: ¬øPuedo cambiar la voz del TTS?**
R: S√≠, explora voces en https://cartesia.ai/voices y cambia `CARTESIA_VOICE_ID` en `.env`.

**P: ¬øEl pipeline funciona offline?**
R: No, requiere conexi√≥n a internet para STT/LLM/TTS. Gemini Live tampoco funciona offline.

**P: ¬øQu√© pasa si me quedo sin cr√©ditos?**
R: El servicio espec√≠fico fallar√° pero la app seguir√° funcionando (telemetr√≠a, overlay, etc.). Ver√°s errores en logs.

---

## üõ†Ô∏è Troubleshooting Avanzado

### Error: "Failed to connect to Deepgram"
- Verificar conectividad a `wss://api.deepgram.com`
- Firewall/antivirus puede bloquear WebSocket
- Probar con otra red

### Error: "OpenRouter stream timeout"
- Red lenta o modelo no disponible
- El fallback a `gpt-4o-mini` deber√≠a activarse autom√°ticamente
- Verificar en https://openrouter.ai/models si Qwen3 est√° activo

### Audio distorsionado o cortado
- Verificar sample rate del mic (debe ser 48kHz o 44.1kHz)
- AudioWorklet puede fallar en algunos navegadores ‚Üí fallback a ScriptProcessor
- Ver logs: `[MicCapture] Using AudioWorklet` o `Using ScriptProcessor`

---

## üìû Soporte

- **Deepgram Docs**: https://developers.deepgram.com/
- **OpenRouter Docs**: https://openrouter.ai/docs
- **Cartesia Docs**: https://docs.cartesia.ai/
- **VICEN Issues**: https://github.com/tu-repo/issues
