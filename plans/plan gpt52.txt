# Migración incremental a pipeline **STT → LLM → TTS** (Deepgram + Claude + Cartesia) sin rehacer la app

## Resumen
Vamos a sustituir el flujo “voice-to-voice” de Gemini Live por un pipeline modular **STT (Deepgram) → LLM (Anthropic Claude) → TTS (Cartesia)**, manteniendo:
- **PTT actual** (F14 toggle) como *mute/unmute* del micro, **no** como fin de turno.
- **Open-mic + endpointing/VAD** para segmentar turnos (silencio) y para **barge‑in** (interrumpir TTS al hablar).
- **Arquitectura continuista**: se reutiliza tu `AudioWorklet`, downsample a 16k, `RadioFX`, telemetría/servidor actual y UI. Gemini Live queda como **fallback** con toggle.

Decisiones fijadas:
- **API keys y llamadas a STT/LLM/TTS en `server/`** (proxy local).
- **Segmentación por endpointing/VAD** (no por PTT).
- **V1 tools: mínimo** (inyectar contexto siempre + tools solo de acción: pit/chat/setup). `compare_laps` queda para V2.

---

## Objetivos y criterios de éxito (Definition of Done)
### Calidad/Comportamiento
- 100% respuestas en **español de España**, sin preámbulos (“Beginning…”, “Let me check…”, etc.).
- Respuesta “radio”: **1–3 frases**, sin markdown/títulos/listas.
- **No cortar** la voz del modelo al hacer PTT OFF; solo se corta si detectamos **voz real** (VAD) o si el usuario vuelve a hablar.

### Latencia (medida y logueada)
- PTT ON → primer parcial STT: < ~500 ms (depende red).
- Final de frase (endpoint) → inicio audio TTS: objetivo < ~1.5 s medio.
- Barge-in (usuario habla mientras TTS suena) → audio se detiene con fade < ~150 ms.

### Estabilidad
- Reconexión automática STT/TTS/LLM con backoff.
- Si falla un proveedor, el resto de la app (telemetría/overlay/spotter) sigue funcionando.

---

## Cambios de arquitectura (continuista, sin rehacer)
### Nuevo canal WebSocket dedicado
- Añadir en `server/src/index.ts` una ruta WS nueva: **`/voice`** (igual que ya haces con `/telemetry` y `/gemini`).
- Este WS es el “bus” entre renderer y pipeline:
  - Renderer envía audio PCM16@16kHz (binario) cuando micro está activo.
  - Server envía audio PCM16@24kHz (binario) para reproducción + mensajes JSON de estado/transcripción.

### Proactividad sin “spamear contextos” al LLM
- Mantener un **ticker** (15s Race / 30s Practice-Qualy) que *actualiza estado y tendencias* en memoria local (server).
- El LLM **solo se invoca** cuando:
  1) hay frase del piloto (STT final), o  
  2) un trigger proactivo decide que “hay algo que decir”.
- Esto conserva proactividad **sin** obligarte a enviar “[CONTEXTO]” como turnos que generan respuestas indeseadas.

---

## Protocolo `/voice` (decision-complete)
### Mensajes JSON (string)
Client → Server:
- `{"type":"hello","protocolVersion":1,"client":"renderer","capabilities":{"binaryAudio":true}}`
- `{"type":"mic_state","enabled":true|false,"mode":"open_mic"}`  (PTT ON/OFF)
- `{"type":"interrupt","reason":"vad_voice"|"ptt_on"}`

Server → Client:
- `{"type":"ready","protocolVersion":1}`
- `{"type":"state","stt":"connected|disconnected","llm":"idle|streaming","tts":"idle|streaming","micEnabled":boolean,"speaking":boolean}`
- `{"type":"stt_partial","text":string,"confidence":number|null}`
- `{"type":"stt_final","text":string,"confidence":number|null}`
- `{"type":"llm_delta","text":string}` *(solo debug/overlay; no obligatorio para UI)*
- `{"type":"llm_done","text":string}`
- `{"type":"error","scope":"stt|llm|tts|pipeline","message":string}`

### Mensajes binarios (ArrayBuffer)
Client → Server:
- Audio mic: **PCM16 little‑endian, 16kHz, mono** (frames ~20–100ms).

Server → Client:
- Audio TTS: **PCM16 little‑endian, 24kHz, mono** (frames según proveedor).

Regla de decodificación en client:
- `event.data` es string ⇒ JSON control.
- `event.data` es ArrayBuffer ⇒ audio PCM16@24kHz para `playAudioChunkFromPCM16()`.

---

## Componentes a crear/modificar (paths concretos)

### Server (Node/TS)
**Nuevos archivos**
1) `server/src/voice/voice-ws.ts`  
   - Crea `VoiceSession` por conexión WS.
   - Enruta JSON/binary, gestiona estados, reconexiones, cola de turnos y aborts.

2) `server/src/voice/providers/deepgram-stt.ts`  
   - Conecta a Deepgram WS (según docs oficiales) con params:
     - `model=nova-2`, `language=es`, `encoding=linear16`, `sample_rate=16000`, `channels=1`
     - `interim_results=true`, `endpointing=300`, `punctuate=true`, `smart_format=true`
     - (opcional) `vad_events=true`
   - Envía audio binario tal cual.
   - Emite eventos: `partial`, `final`.
   - En “mic_state enabled=false” envía `{"type":"Finalize"}` y deja de enviar audio.

3) `server/src/voice/providers/anthropic-llm.ts`  
   - Cliente para `POST /v1/messages` con `stream: true` (SSE).
   - Usa `AbortController` para cancelar en barge‑in.
   - Implementa tool calling **solo de acción** (V1):
     - `configure_pit_stop`, `get_pit_status`, `send_chat_macro`, `request_current_setup`
   - Parser SSE (event types de Anthropic docs): acumula texto y detecta `stop_reason`.

4) `server/src/voice/providers/cartesia-tts.ts`  
   - Conecta a Cartesia WS.
   - Implementa streaming con **continuations** usando `context_id`:
     - Primer chunk: `continue=false`
     - Siguientes: `continue=true`
   - Recibe `data` base64 PCM y lo convierte a `Buffer` para enviar binario al client.
   - Soporta cancelación: si llega `interrupt`, envía cancel (según API) y corta cola.

5) `server/src/voice/context/race-state.ts`  
   - Mantiene:
     - `latestTelemetry` (snapshot), `prevTickTelemetry`
     - deltas/trends (gapRate, fuelRate, etc.)
     - cooldowns de proactividad
   - Función `shouldSpeakProactively()` que devuelve trigger (o null).

6) `server/src/voice/prompts/system.ts`  
   - System prompt **corto** (≤ ~1–2k chars) con:
     - Español España obligatorio
     - Sin preámbulos / sin tool mention / radio style / máximo N frases
     - “No repitas datos visibles salvo que te lo pidan”
   - La “inteligencia de proactividad” se basa más en `race-state.ts` que en prompt.

7) `server/src/voice/utils/text-chunker.ts`  
   - Convierte stream de texto del LLM en segmentos “TTS-friendly” (frases por puntuación) y límite duro (p.ej. 180–220 chars).
   - Nunca corta en medio de palabra; prioriza `.?!\n`.

8) `server/src/voice/utils/output-sanitizer.ts`  
   - Limpia: títulos, markdown, listas, frases prohibidas, comillas raras.
   - Enforce: 1–3 frases, español.  
   - Si detecta inglés fuerte ⇒ 1 reintento con “rewrite in es-ES, plain text”.

**Cambios en archivos existentes**
- `server/src/index.ts`
  - Añadir `voiceWss = new WebSocketServer({ noServer: true, perMessageDeflate: false })`.
  - En `httpServer.on('upgrade')` routear `/voice`.
  - Instanciar/adjuntar `attachVoiceWs(voiceWss, deps...)`.
  - Mejorar caché de telemetría: exponer helper `getLatestTelemetryData()` que siempre devuelva `message.data` cuando el último mensaje sea `snapshot/event`.

- (Opcional pero recomendado) refactor de comandos python:
  - Crear `server/src/python-commands.ts` con funciones promise-based para pit/chat/status usando `pythonTelemetryWs` y `pendingCommands`.
  - Permite que el LLM (en server) ejecute tools sin depender del client.

### Client (React/Vite)
**Nuevos archivos**
1) `client/src/services/voice/voice-pipeline.ts`
   - Conecta a `ws://localhost:8081/voice`.
   - Expone:
     - `connect()/disconnect()`
     - `setMicEnabled(true|false)` (desde PTT)
     - callbacks: `onTranscriptPartial`, `onTranscriptFinal`, `onSpeakingState`, `onError`
   - Recibe audio binario y lo pasa a playback.

2) `client/src/services/voice/mic-capture.ts`
   - Reutiliza `AudioWorklet` (`/audio-processor.js`) y el downsample existente (copiado o extraído).
   - Convierte `Float32Array` → PCM16 ArrayBuffer y envía binario por WS.
   - Mantiene VAD (RMS→dB) para:
     - `interrupt` cuando hay voz mientras TTS suena (barge‑in).

3) `client/src/services/voice/audio-playback.ts`
   - Reutiliza la cadena RadioFX del `GeminiLiveService` (copiar/extraer).
   - Añade `playPcm16Chunk(buffer, sampleRate=24000)` que usa `pcm16ToFloat32()` y `AudioBuffer`.

**Cambios en archivos existentes**
- `client/src/App.tsx`
  - Añadir selección de engine: `import.meta.env.VITE_VOICE_ENGINE` (`'gemini'|'pipeline'`).
  - Si engine=`pipeline`:
    - instanciar `VoicePipelineService`
    - en `PTT_PRESS` ⇒ `setMicEnabled(true)` (no cortar TTS)
    - en `PTT_RELEASE` ⇒ `setMicEnabled(false)` (no dispara respuesta; el endpointing ya finaliza)
  - Mantener Gemini Live intacto como fallback.

- (Opcional) UI/estado
  - Reusar `ConnectionStatus` o extender para mostrar `STT/LLM/TTS`.

---

## Variables de entorno (seguras)
**Server (.env.local o variables del entorno del proceso)**
- `DEEPGRAM_API_KEY=...`
- `ANTHROPIC_API_KEY=...`
- `CARTESIA_API_KEY=...`
- `ANTHROPIC_MODEL=claude-3-5-haiku-20241022` *(configurable; no hardcode en código)*
- `DEEPGRAM_MODEL=nova-2`
- `CARTESIA_MODEL_ID=sonic-3-turbo`
- `CARTESIA_VOICE_ID=...` *(o voice preset)*
- `VOICE_LOG_LEVEL=info|debug`

**Client (.env / .env.local)**
- `VITE_VOICE_ENGINE=pipeline|gemini` *(solo selección; sin keys)*

---

## Proactividad (cómo se implementa sin romper conversación)
- `race-state.ts` guarda tick anterior y actual (15s/30s) y calcula:
  - evolución de gaps (Δ y rate)
  - fuel: laps estimadas con avg (si hay datos)
  - flags/posición/eventos recientes (de mensajes `event`)
- Triggers V1 (decision complete):
  - `flag_change` (prioridad alta, sin cooldown)
  - `position_change` (cooldown 20–30s)
  - `gap_delta_abs > 0.5s` entre ticks (cooldown 45s)
  - `incident` (alta)
- Cuando trigger dispara:
  - Si `micEnabled && voz detectada` ⇒ no hablar (se pospone o se descarta).
  - Si `tts streaming` ⇒ se encola o se descarta según prioridad.
  - Si ejecuta, llama LLM con `task=PROACTIVE` + estado compacto.

---

## LLM: formato de entrada/salida (para máxima obediencia)
### Entrada por llamada
- System: persona + reglas cortas.
- User content incluye:
  1) `[STATE]` JSON compacto (telemetría + trends + sesión).
  2) `[USER]` transcript final (o `[EVENT]` si proactivo).
- Tools: solo acciones (V1).

### Salida obligatoria (enforced en prompt + sanitizer)
- Texto plano, español, 1–3 frases, sin markdown, sin “voy a…”, sin “déjame…”.

---

## Estrategia de implementación (paso a paso)
1) **Cableado WS `/voice`** en server + `VoicePipelineService` en client con “echo” (sin STT/LLM/TTS): valida conexión, JSON state, audio binary roundtrip.
2) **Mic capture**: reutilizar AudioWorklet + downsample → enviar PCM16 binario al server; medir throughput/CPU.
3) **STT Deepgram**: server recibe audio y reenvía; client muestra parciales/finales; ajustar endpointing.
4) **LLM Anthropic (stream)**: al STT final, llamar LLM con estado compacto; emitir `llm_delta` a client.
5) **TTS Cartesia (stream + continuations)**: chunker + TTS streaming; reproducir en client con RadioFX.
6) **Barge‑in**: VAD en client → `interrupt` → server abort LLM + cancel TTS + client fade-out.
7) **Proactividad**: ticker + triggers + cooldowns + llamadas LLM “proactive”.
8) **Tools de acción (V1)**: implementar tool calling de pit/chat/setup (server-side).
9) **Toggle engine + rollback**: UI/env para cambiar pipeline↔Gemini.

---

## Test plan (manual, reproducible)
1) **STT**: PTT ON, decir “¿Cuál es mi gap con el de delante?” → `stt_final` correcto en es-ES.
2) **Turnos por silencio**: con mic abierto, decir 2 frases separadas por pausa >300ms → 2 respuestas distintas sin tocar PTT.
3) **Barge-in**: durante TTS, hablar encima → audio se corta con fade <150ms y empieza nueva captura.
4) **No cortes por PTT OFF**: mientras el modelo habla, PTT OFF no corta audio.
5) **Proactividad**: simular `flag_change` (o esperar evento real) → mensaje corto, no spam.
6) **Tools acción**: “pon 5 litros” / “quita gomas” / “macro 3” → tool_use → tool_result → respuesta hablada.
7) **Resiliencia**: cortar red (o API key inválida) → `error` y la app sigue; reconecta al restaurar.

---

## Rollback (5 minutos)
- Mantener Gemini Live intacto.
- `VITE_VOICE_ENGINE=gemini` o toggle UI.
- Reiniciar app.

---

## Supuestos
- El renderer seguirá siendo el único que reproduce audio (AudioContext + RadioFX).
- La telemetría ya llega al server (Python→Node) y podemos construir estado desde ahí.
- Los proveedores se acceden desde el host (no hay bloqueo de firewall a WS/SSE).

